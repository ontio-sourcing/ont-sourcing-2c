#
spring.application.name=ont-sourcing-2c
spring.http.encoding.charset=UTF-8
spring.http.encoding.enabled=true
spring.http.encoding.force=true
#
spring.main.allow-bean-definition-overriding=true
#
server.port=9088

##### 日志 #####
#
logging.config=classpath:logback-spring.xml
# 日志根目录
log.custom.dir=/home/ubuntu/ont-sourcing-2c/log
# 日志级别
log.custom.root.level=DEBUG
# 文件大小，默认50MB
log.custom.max_file_size=100MB
# 滚动时间 ，默认只保留最近 10 天的日志
log.custom.max_history=100


##### 数据库 #####
#
spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/ont-sourcing-2c?useUnicode=true&characterEncoding=UTF-8&zeroDateTimeBehavior=convertToNull&serverTimezone=UTC
spring.datasource.username=root
spring.datasource.password=ontsoure_passwd
# Hikari will use the above plus the following to setup connection pooling
spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.maximum-pool-size=100
spring.datasource.hikari.auto-commit=true
spring.datasource.hikari.idle-timeout=30000
spring.datasource.hikari.pool-name=MyHikariCP
spring.datasource.hikari.max-lifetime=1800000
spring.datasource.hikari.connection-timeout=30000
spring.datasource.hikari.connection-test-query=SELECT 1
# JPA Configuration:
spring.jpa.database=MYSQL
spring.jpa.show-sql=false
spring.jpa.generate-ddl=true
spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5Dialect
#
com.ontology.sourcing.TABLE_SIZE_DETECT_INTERVAL=100000
com.ontology.sourcing.TABLE_SIZE_LIMIT=50

##### ontology地址 #####
com.ontology.sourcing.ONTOLOGY_URL_LIST=http://polaris1.ont.io,http://polaris2.ont.io,http://polaris3.ont.io,http://polaris4.ont.io,http://polaris5.ont.io

##### 钱包路径 #####
com.ontology.sourcing.WALLET_PATH=/home/ubuntu/ont-sourcing/config/wallet.json


##### 公共存证 #####
# 智能合约地址
com.ontology.sourcing.CONTRACT_CODE_ADDRESS=e2510ed1044503faf6e3e66b98372606bbeae38f


##### RFC3161时间戳 #####
com.ontology.sourcing.TIMESTAMP_URL_LIST=http://120.76.22.235:8081/api/rfc3161,http://sha256timestamp.ws.symantec.com/sha256/timestamp,http://timestamp.comodoca.com/rfc3161,http://112.74.16.78:8090/tss/tsa,http://timestamp.sheca.com/Timestamp/pdftime.do

##### ontid_server #####
com.ontology.sourcing.ontid.rsa.publicKey=TUlHZk1BMEdDU3FHU0liM0RRRUJBUVVBQTRHTkFEQ0JpUUtCZ1FDZHlOakVpekVQdzdjdWRsL3dZMlVGZzlnaE5qL2pSMDRpQzhIM1crU1dML0dNQ25Pei85WERmQzN1ODRUdnQxS2dGcVdJWkl3a2dOSmxNVFhIZWRTWElNWDkxalUwbUdJSGlVY21SbWdyNTZKYjFCNUMxM3REK1VUQTRpaTYzV0ttRCtBRXZ4ZWp4U3BodXlaMk1JTGxOcUlJdUw3MWdrbFNrWWtUYlhzWEdRSURBUUFC
com.ontology.sourcing.ontid.rsa.privateKey=
com.ontology.sourcing.ontid.aes.iv=Njg4OWY4OTJhMTdlNDM3MQ==
com.ontology.sourcing.ontid.aes.contractKey=
#
com.ontology.sourcing.ontid.app.id=mdgDyjj4
com.ontology.sourcing.ontid.app.secret=g6VD0d8oBTfuUa2z1RSBoQ==
#
com.ontology.sourcing.ontid.app.host=http://139.219.136.188:10331
com.ontology.sourcing.ontid.app.path.register=/inner/v1/ontid/register
# 通过 手机号 注册 ontid，写死的密码
com.ontology.sourcing.ontid.app.phone.password=12345678aA
# 验 access_token
com.ontology.sourcing.ONTID_PUBLIC_KEY=026d3557e55fffe7bc5a9a8fc0c7361bc48590c17bf4d0d345e3f354bb64a0452a

##### 管理 项目方定制合约和秘钥接口 的口令 #####
com.ontology.sourcing.ONT_PASSWORD=123456

#============== kafka ===================
# 指定kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=172.168.3.71:9092

##### provider #####
#
spring.kafka.producer.acks=1
spring.kafka.producer.retries=0
#
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
#
spring.kafka.producer.contractKey-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

##### consumer #####
#
spring.kafka.consumer.group-id=test_group_0514-2c
#
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false
#spring.kafka.consumer.auto-commit-interval=1S
#
spring.kafka.consumer.contractKey-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 批量一次最大拉取数据量 TODO 每次还不一定拉10
spring.kafka.consumer.max-poll-records=10

##### #####
#
spring.kafka.listener.ack-mode=manual
spring.kafka.listener.concurrency=10